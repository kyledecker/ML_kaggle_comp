{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kyle Decker\n",
    "STA561 -  Probabilistic Machine Learning  \n",
    "Kaggle Competition Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import time\n",
    "import warnings\n",
    "import pylab\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data and perform minor preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in training and test data\n",
    "train_tmp = pd.read_csv('pml_train.csv')\n",
    "test_tmp = pd.read_csv('pml_test_features.csv')\n",
    "\n",
    "# Drop the loss col temporarily in order to merge data frames\n",
    "loss = train_tmp['loss']\n",
    "train_tmp.drop(labels=['loss'], axis=1,inplace = True)\n",
    "\n",
    "# Cat the training and test in order to convert categorical vars to dummies\n",
    "frames = [train_tmp,test_tmp]\n",
    "data_tmp = pd.concat(frames) \n",
    "\n",
    "# Convert categorical features to dummy vars\n",
    "data_dummy = pd.get_dummies(data_tmp)\n",
    "\n",
    "# Split back in to train and test\n",
    "train_size = len(train_tmp['id'])\n",
    "train = data_dummy.iloc[0:train_size,:]\n",
    "test = data_dummy.iloc[train_size:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis and Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get some summary stats\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the categorical features that have very few instances (<10000)\n",
    "cols_to_drop = []\n",
    "for i in range(len(train.iloc[1])):\n",
    "    if (np.count_nonzero(train.iloc[:,i]) < 10000):\n",
    "        cols_to_drop = np.append(cols_to_drop,i)\n",
    "train.drop(train.columns[cols_to_drop.astype(int)],axis=1,inplace = True)\n",
    "test.drop(test.columns[cols_to_drop.astype(int)],axis=1,inplace = True)\n",
    "\n",
    "# Move the loss to column 0\n",
    "train.insert(0, 'loss', loss)\n",
    "\n",
    "# randomly partition data into train_sub (80%) and cross_val (20%) sets\n",
    "train_sub,cross_val = train_test_split(train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot of continuous vars\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12, ax13, ax14) = plt.subplots(14, sharex=True, sharey=True)\n",
    "ax1.scatter(train['cont1'],train['loss'])\n",
    "f, (ax1).title.set_text('cont1')\n",
    "ax2.scatter(train['cont2'],train['loss'])\n",
    "f, (ax2).title.set_text('cont2')\n",
    "ax3.scatter(train['cont3'],train['loss'])\n",
    "f, (ax3).title.set_text('cont3')\n",
    "ax4.scatter(train['cont4'],train['loss'])\n",
    "f, (ax4).title.set_text('cont4')\n",
    "ax5.scatter(train['cont5'],train['loss'])\n",
    "f, (ax5).title.set_text('cont5')\n",
    "ax6.scatter(train['cont6'],train['loss'])\n",
    "f, (ax6).title.set_text('cont6')\n",
    "ax7.scatter(train['cont7'],train['loss'])\n",
    "f, (ax7).title.set_text('cont6')\n",
    "ax8.scatter(train['cont8'],train['loss'])\n",
    "f, (ax8).title.set_text('cont8')\n",
    "ax9.scatter(train['cont9'],train['loss'])\n",
    "f, (ax9).title.set_text('cont9')\n",
    "ax10.scatter(train['cont10'],train['loss'])\n",
    "f, (ax10).title.set_text('cont10')\n",
    "ax11.scatter(train['cont11'],train['loss'])\n",
    "f, (ax11).title.set_text('cont11')\n",
    "ax12.scatter(train['cont12'],train['loss'])\n",
    "f, (ax12).title.set_text('cont12')\n",
    "ax13.scatter(train['cont13'],train['loss'])\n",
    "f, (ax13).title.set_text('cont13')\n",
    "ax14.scatter(train['cont14'],train['loss'])\n",
    "f, (ax14).title.set_text('cont14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some features seem highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont11 and cont12 are highly correlated with r2 score of 0.988691\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAE4CAYAAADW9AHMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsxIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116123d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot two variables against eachother that seem correlated\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 5\n",
    "fig_size[1] = 5\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.scatter(train['cont11'],train['cont12'])\n",
    "# Determine correlation r2 between the two variables\n",
    "r2 = r2_score(train['cont11'],train['cont12'])\n",
    "print('cont11 and cont12 are highly correlated with r2 score of %f' %r2)\n",
    "# PCA should take care of these but lets drop one of them just in case\n",
    "train.drop(labels=['cont11'], axis=1,inplace = True)\n",
    "train_sub.drop(labels=['cont11'], axis=1,inplace = True)\n",
    "cross_val.drop(labels=['cont11'], axis=1,inplace = True)\n",
    "test.drop(labels=['cont11'], axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA to perform dimensionality reduction and take care of correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca= decomposition.PCA(n_components=75)\n",
    "train_pca = pca.fit_transform(train.iloc[:,2:])\n",
    "train_sub_pca = pca.transform(train_sub.iloc[:,2:])\n",
    "cross_val_pca = pca.transform(cross_val.iloc[:,2:])\n",
    "test_pca = pca.transform(test.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "#rf = RandomForestRegressor(n_estimators = 5, criterion='mse',min_samples_leaf=10,max_features = 100, random_state = 3)\n",
    "rf = RandomForestRegressor(n_estimators = 1000, criterion='mse',min_samples_leaf=10,min_samples_split=50,max_features = 100, random_state = 3)\n",
    "#rf = RandomForestRegressor(n_estimators = 100, criterion='mse',min_samples_split=40,min_samples_leaf=20,max_features = 40, random_state = 3)\n",
    "#rf = RandomForestRegressor(n_estimators = 5, criterion='mse',min_samples_leaf=15,max_features = 100) \n",
    "\n",
    "start_time = time.time()\n",
    "# train the model\n",
    "rf.fit(train_sub.iloc[:,2:],train_sub.iloc[:,0])\n",
    "#rf.fit(train_sub_pca,train_sub.iloc[:,0])\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Model trained in  %f seconds' % elapsed_time)\n",
    "\n",
    "# predict the loss for training and cross validation\n",
    "loss_pred_train = rf.predict(train_sub.iloc[:,2:])\n",
    "#loss_pred_train = rf.predict(train_sub_pca)\n",
    "MAE_train = mean_absolute_error(train_sub.iloc[:,0],loss_pred_train)\n",
    "print('MAE on training set = %f' % MAE_train)\n",
    "\n",
    "loss_pred_cv = rf.predict(cross_val.iloc[:,2:])\n",
    "#loss_pred_cv = rf.predict(cross_val_pca)\n",
    "MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "print('MAE on cross validation set = %f' % MAE_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose Number of Trees\n",
    "trees = [1,3,10,30,100]\n",
    "train_error_all = []\n",
    "cv_error_all = []\n",
    "size = 1000;\n",
    "for i in range(len(trees)):\n",
    "    rf = RandomForestRegressor(n_estimators = trees[i], random_state = 3)\n",
    "    rf.fit(train_sub.iloc[:size,2:],train_sub.iloc[:size,0])\n",
    "    loss_pred_train = rf.predict(train_sub.iloc[:size,2:])\n",
    "    MAE_train = mean_absolute_error(train_sub.iloc[:size,0],loss_pred_train)\n",
    "    loss_pred_cv = rf.predict(cross_val.iloc[:,2:])\n",
    "    MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "    \n",
    "    train_error_all = np.append(train_error_all,MAE_train)\n",
    "    cv_error_all = np.append(cv_error_all,MAE_cv)\n",
    "\n",
    "pylab.plot(trees,train_error_all,'b--',label='training')\n",
    "pylab.plot(trees,cv_error_all,'r--',label='cross-validation')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.xlabel('Number of trees')\n",
    "pylab.ylabel('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose Min Samples to Split\n",
    "splits = [2,4,16,40,100]\n",
    "train_error_all = []\n",
    "cv_error_all = []\n",
    "size = 1000;\n",
    "for i in range(len(trees)):\n",
    "    rf = RandomForestRegressor(n_estimators = 100, min_samples_split=splits[i], random_state = 3)\n",
    "    rf.fit(train_sub.iloc[:size,2:],train_sub.iloc[:size,0])\n",
    "    loss_pred_train = rf.predict(train_sub.iloc[:size,2:])\n",
    "    MAE_train = mean_absolute_error(train_sub.iloc[:size,0],loss_pred_train)\n",
    "    loss_pred_cv = rf.predict(cross_val.iloc[:,2:])\n",
    "    MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "    \n",
    "    train_error_all = np.append(train_error_all,MAE_train)\n",
    "    cv_error_all = np.append(cv_error_all,MAE_cv)\n",
    "\n",
    "pylab.plot(splits,train_error_all,'b--',label='training')\n",
    "pylab.plot(splits,cv_error_all,'r--',label='cross-validation')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.xlabel('Min Samples to Split')\n",
    "pylab.ylabel('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose Min Samples at Leaf\n",
    "leaf = [1,3,10,30,100]\n",
    "train_error_all = []\n",
    "cv_error_all = []\n",
    "size = 1000;\n",
    "for i in range(len(trees)):\n",
    "    rf = RandomForestRegressor(n_estimators = 100, min_samples_split=100,min_samples_leaf=leaf[i], random_state = 3)\n",
    "    rf.fit(train_sub.iloc[:size,2:],train_sub.iloc[:size,0])\n",
    "    loss_pred_train = rf.predict(train_sub.iloc[:size,2:])\n",
    "    MAE_train = mean_absolute_error(train_sub.iloc[:size,0],loss_pred_train)\n",
    "    loss_pred_cv = rf.predict(cross_val.iloc[:,2:])\n",
    "    MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "    \n",
    "    train_error_all = np.append(train_error_all,MAE_train)\n",
    "    cv_error_all = np.append(cv_error_all,MAE_cv)\n",
    "\n",
    "pylab.plot(leaf,train_error_all,'b--',label='training')\n",
    "pylab.plot(leaf,cv_error_all,'r--',label='cross-validation')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.xlabel('Min Samples at Leaf')\n",
    "pylab.ylabel('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose Max Features to consider\n",
    "feat = [2,4,16,40,100]\n",
    "train_error_all = []\n",
    "cv_error_all = []\n",
    "size = 1000;\n",
    "for i in range(len(trees)):\n",
    "    rf = RandomForestRegressor(n_estimators = 100, min_samples_split=100,min_samples_leaf=20,max_features = feat[i], random_state = 3)\n",
    "    rf.fit(train_sub.iloc[:size,2:],train_sub.iloc[:size,0])\n",
    "    loss_pred_train = rf.predict(train_sub.iloc[:size,2:])\n",
    "    MAE_train = mean_absolute_error(train_sub.iloc[:size,0],loss_pred_train)\n",
    "    loss_pred_cv = rf.predict(cross_val.iloc[:,2:])\n",
    "    MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "    \n",
    "    train_error_all = np.append(train_error_all,MAE_train)\n",
    "    cv_error_all = np.append(cv_error_all,MAE_cv)\n",
    "\n",
    "pylab.plot(feat,train_error_all,'b--',label='training')\n",
    "pylab.plot(feat,cv_error_all,'r--',label='cross-validation')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.xlabel('Max Features to Consider for Split')\n",
    "pylab.ylabel('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try on the test set and make kaggle output\n",
    "loss_pred_test = rf.predict(test.iloc[:,1:])\n",
    "#loss_pred_test = rf.predict(test_pca)\n",
    "\n",
    "test_results_id = test['id']\n",
    "test_results_loss = loss_pred_test\n",
    "\n",
    "# Create results data frame\n",
    "test_df = pd.DataFrame(data=test_results_id)\n",
    "test_df.insert(1, 'loss', test_results_loss)\n",
    "\n",
    "# Save output to csv format\n",
    "test_df.to_csv('RF_results.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "lasso = Lasso(alpha=0.1);\n",
    "\n",
    "pca_bool = True;\n",
    "\n",
    "x_train = train_sub_pca\n",
    "x_cv = cross_val_pca\n",
    "\n",
    "if (pca_bool == True):\n",
    "    lasso.fit(x_train,train_sub.iloc[:,0])\n",
    "    loss_pred_train = lasso.predict(x_train)\n",
    "    loss_pred_cv = lasso.predict(x_cv)\n",
    "else:\n",
    "    lasso.fit(train_sub.iloc[:,2:],train_sub.iloc[:,0])\n",
    "    loss_pred_train = lasso.predict(train_sub.iloc[:,2:])\n",
    "    loss_pred_cv = lasso.predict(cross_val.iloc[:,2:])\n",
    "\n",
    "# predict the loss for training and cross validation\n",
    "MAE_train = mean_absolute_error(train_sub.iloc[:,0],loss_pred_train)\n",
    "print('MAE on training set = %f' % MAE_train)\n",
    "\n",
    "MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "print('MAE on cross validation set = %f' % MAE_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try on the test set and make kaggle output\n",
    "loss_pred_test = lasso.predict(test_pca)\n",
    "\n",
    "test_results_id = test['id']\n",
    "test_results_loss = loss_pred_test\n",
    "\n",
    "# Create results data frame\n",
    "test_df = pd.DataFrame(data=test_results_id)\n",
    "test_df.insert(1, 'loss', test_results_loss)\n",
    "\n",
    "# Save output to csv format\n",
    "test_df.to_csv('LASSO_results.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "svr = SVR(kernel='rbf', epsilon = 0.1);\n",
    "#svr = SVR(kernel='poly', degree=2);\n",
    "size = 100;\n",
    "svr.fit(train_sub_pca[0:size,:],train_sub.iloc[0:size,0])\n",
    "\n",
    "# predict the loss for training and cross validation\n",
    "#loss_pred_train = rf.predict(train_sub.iloc[:,2:])\n",
    "loss_pred_train = svr.predict(train_sub_pca)\n",
    "MAE_train = mean_absolute_error(train_sub.iloc[:,0],loss_pred_train)\n",
    "print('MAE on training set = %f' % MAE_train)\n",
    "\n",
    "#loss_pred_cv = rf.predict(cross_val.iloc[:,2:])\n",
    "loss_pred_cv = svr.predict(cross_val_pca)\n",
    "MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "print('MAE on cross validation set = %f' % MAE_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2,interaction_only=True)\n",
    "x = poly.fit_transform(train_sub_pca)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bayesian regression w/ poly features\n",
    "br = BayesianRidge();\n",
    "\n",
    "x_poly = poly.transform(train_sub_pca)\n",
    "cv_poly = poly.transform(cross_val_pca)\n",
    "\n",
    "br.fit(x_poly,train_sub.iloc[:,0])\n",
    "\n",
    "# predict the loss for training and cross validation\n",
    "#loss_pred_train = br.predict(train_sub_pca)\n",
    "loss_pred_train = br.predict(x_poly)\n",
    "MAE_train = mean_absolute_error(train_sub.iloc[:,0],loss_pred_train)\n",
    "print('MAE on training set = %f' % MAE_train)\n",
    "\n",
    "#loss_pred_cv = br.predict(cross_val_pca)\n",
    "loss_pred_cv = br.predict(cv_poly)\n",
    "MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "print('MAE on cross validation set = %f' % MAE_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try on the test set and make kaggle output\n",
    "loss_pred_test = br.predict(poly.transform(test_pca))\n",
    "\n",
    "test_results_id = test['id']\n",
    "test_results_loss = loss_pred_test\n",
    "\n",
    "# Create results data frame\n",
    "test_df = pd.DataFrame(data=test_results_id)\n",
    "test_df.insert(1, 'loss', test_results_loss)\n",
    "\n",
    "# Save output to csv format\n",
    "test_df.to_csv('Poly_Bayesian_results.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multi-layer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# MLP Regressor\n",
    "#nn = MLPRegressor(hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100, 100, 100),alpha= 0.0001, activation = 'relu',random_state = 13)\n",
    "#nn = MLPRegressor(hidden_layer_sizes=(30, 30, 30,), activation = 'relu',alpha= 0.3, random_state = 3)\n",
    "nn = MLPRegressor(hidden_layer_sizes=(30, 30, 30,), activation = 'relu',alpha= 0.3, random_state = 6)\n",
    "\n",
    "start_time = time.time()\n",
    "# train the model\n",
    "nn.fit(train_sub.iloc[0:,2:],train_sub.iloc[0:,0])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Model trained in  %f seconds' % elapsed_time)\n",
    "\n",
    "# predict the loss for training and cross validation\n",
    "loss_pred_train = nn.predict(train_sub.iloc[:,2:])\n",
    "\n",
    "MAE_train = mean_absolute_error(train_sub.iloc[:,0],loss_pred_train)\n",
    "print('MAE on training set = %f' % MAE_train)\n",
    "\n",
    "loss_pred_cv = nn.predict(cross_val.iloc[:,2:]) \n",
    "\n",
    "    \n",
    "MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "print('MAE on cross validation set = %f' % MAE_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose Activation Function\n",
    "act = ['identity', 'logistic', 'tanh', 'relu']\n",
    "train_error_all = []\n",
    "cv_error_all = []\n",
    "size = 1000;\n",
    "for i in range(len(act)):\n",
    "    nn = MLPRegressor(activation = act[i])\n",
    "    nn.fit(train_sub.iloc[:size,2:],train_sub.iloc[:size,0])\n",
    "    loss_pred_train = nn.predict(train_sub.iloc[:size,2:])\n",
    "    MAE_train = mean_absolute_error(train_sub.iloc[:size,0],loss_pred_train)\n",
    "    loss_pred_cv = nn.predict(cross_val.iloc[:,2:])\n",
    "    MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "    \n",
    "    train_error_all = np.append(train_error_all,MAE_train)\n",
    "    cv_error_all = np.append(cv_error_all,MAE_cv)\n",
    "\n",
    "print(cv_error_all)\n",
    "print(train_error_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose Number of Hidden Layers\n",
    "num_layers = [1,3,10]\n",
    "\n",
    "train_error_all = []\n",
    "cv_error_all = []\n",
    "size = 1000;\n",
    "for i in range(len(num_layers)):\n",
    "    if (i ==0):\n",
    "        nn = MLPRegressor(activation = 'relu', hidden_layer_sizes=(100,))\n",
    "    elif (i == 1):\n",
    "        nn = MLPRegressor(activation = 'relu', hidden_layer_sizes=(100,100,100,))\n",
    "    elif (i == 2):\n",
    "        nn = MLPRegressor(activation = 'relu', hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100,))\n",
    "    nn.fit(train_sub.iloc[:size,2:],train_sub.iloc[:size,0])\n",
    "    loss_pred_train = nn.predict(train_sub.iloc[:size,2:])\n",
    "    MAE_train = mean_absolute_error(train_sub.iloc[:size,0],loss_pred_train)\n",
    "    loss_pred_cv = nn.predict(cross_val.iloc[:,2:])\n",
    "    MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "    \n",
    "    train_error_all = np.append(train_error_all,MAE_train)\n",
    "    cv_error_all = np.append(cv_error_all,MAE_cv)\n",
    "\n",
    "pylab.plot(num_layers,train_error_all,'b--',label='training')\n",
    "pylab.plot(num_layers,cv_error_all,'r--',label='cross-validation')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.xlabel('Number of Hidden Layers')\n",
    "pylab.ylabel('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose Hidden Layer Size\n",
    "layer_size = [3,10,30,100]\n",
    "\n",
    "train_error_all = []\n",
    "cv_error_all = []\n",
    "size = 1000;\n",
    "for i in range(len(layer_size)):\n",
    "    nn = MLPRegressor(activation = 'relu', hidden_layer_sizes=(layer_size[i],layer_size[i],layer_size[i],))\n",
    "    nn.fit(train_sub.iloc[:size,2:],train_sub.iloc[:size,0])\n",
    "    loss_pred_train = nn.predict(train_sub.iloc[:size,2:])\n",
    "    MAE_train = mean_absolute_error(train_sub.iloc[:size,0],loss_pred_train)\n",
    "    loss_pred_cv = nn.predict(cross_val.iloc[:,2:])\n",
    "    MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "    \n",
    "    train_error_all = np.append(train_error_all,MAE_train)\n",
    "    cv_error_all = np.append(cv_error_all,MAE_cv)\n",
    "\n",
    "pylab.plot(layer_size,train_error_all,'b--',label='training')\n",
    "pylab.plot(layer_size,cv_error_all,'r--',label='cross-validation')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.xlabel('Number of Neurons in each Hidden layer')\n",
    "pylab.ylabel('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try on the test set and make kaggle output\n",
    "loss_pred_test = nn.predict(test.iloc[:,1:])\n",
    "#loss_pred_test = rf.predict(test_pca)\n",
    "\n",
    "test_results_id = test['id']\n",
    "test_results_loss = loss_pred_test\n",
    "\n",
    "# Create results data frame\n",
    "test_df = pd.DataFrame(data=test_results_id)\n",
    "test_df.insert(1, 'loss', test_results_loss)\n",
    "\n",
    "# Save output to csv format\n",
    "test_df.to_csv('NN_results.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine MLP and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine RF and MLP \n",
    "loss_pred_cv_rf = rf.predict(cross_val.iloc[:,2:])\n",
    "loss_pred_cv_nn = nn.predict(cross_val.iloc[:,2:])\n",
    "loss_pred_cv = (loss_pred_cv_rf + loss_pred_cv_nn)/2\n",
    "#loss_pred_cv = rf.predict(cross_val_pca)\n",
    "MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "print('MAE on cross validation set = %f' % MAE_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try on the test set and make kaggle output\n",
    "loss_pred_test = (nn.predict(test.iloc[:,1:]) + rf.predict(test.iloc[:,1:]))/2\n",
    "#loss_pred_test = rf.predict(test_pca)\n",
    "\n",
    "test_results_id = test['id']\n",
    "test_results_loss = loss_pred_test\n",
    "\n",
    "# Create results data frame\n",
    "test_df = pd.DataFrame(data=test_results_id)\n",
    "test_df.insert(1, 'loss', test_results_loss)\n",
    "\n",
    "# Save output to csv format\n",
    "test_df.to_csv('NN_RF_combo_results.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in  5757.271246 seconds\n",
      "MAE on training set = 611.610900\n",
      "MAE on cross validation set = 1357.167168\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adaboost\n",
    "ab = AdaBoostRegressor(DecisionTreeRegressor(max_depth=20),\n",
    "                          n_estimators=1000, random_state=3)\n",
    "\n",
    "#ab= AdaBoostRegressor(MLPRegressor(hidden_layer_sizes=(30, 30, 30,), activation = 'relu',alpha= 0.3), n_estimators=5, random_state=6)\n",
    "\n",
    "start_time = time.time()\n",
    "# train the model\n",
    "ab.fit(train_sub.iloc[0:,2:],train_sub.iloc[0:,0])\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Model trained in  %f seconds' % elapsed_time)\n",
    "\n",
    "# predict the loss for training and cross validation\n",
    "loss_pred_train = ab.predict(train_sub.iloc[:,2:])\n",
    "\n",
    "MAE_train = mean_absolute_error(train_sub.iloc[:,0],loss_pred_train)\n",
    "print('MAE on training set = %f' % MAE_train)\n",
    "\n",
    "loss_pred_cv = ab.predict(cross_val.iloc[:,2:]) \n",
    "\n",
    "    \n",
    "MAE_cv = mean_absolute_error(cross_val.iloc[:,0],loss_pred_cv)\n",
    "print('MAE on cross validation set = %f' % MAE_cv)\n",
    "\n",
    "# Try on the test set and make kaggle output\n",
    "loss_pred_test = ab.predict(test.iloc[:,1:])\n",
    "#loss_pred_test = rf.predict(test_pca)\n",
    "\n",
    "test_results_id = test['id']\n",
    "test_results_loss = loss_pred_test\n",
    "\n",
    "# Create results data frame\n",
    "test_df = pd.DataFrame(data=test_results_id)\n",
    "test_df.insert(1, 'loss', test_results_loss)\n",
    "\n",
    "# Save output to csv format\n",
    "test_df.to_csv('Adaboost_results.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
